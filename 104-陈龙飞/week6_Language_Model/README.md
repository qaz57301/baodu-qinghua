1.参考老师的代码，将ngram语言模型替换为nnlm语言模型来实现文本纠错

2.语言模型采用老师提供的“财经.txt”来构造字表及训练参数

3.模型训练时，经过RNN层后，采用RNN层输出的第2个值进行下一层的训练，即采用最后输出的隐向量进行下一层的训练。
  因为RNN是2层，所以最后输出的是2个隐向量构成的列表，第1个隐向量是第1层RNN的输出，第2个隐向量是第2层RNN的输出。
  取第2层的隐向量参与之后的训练，相关代码如下：
  _, x = self.layer(x)
  x = x[1]

4.经调试参数，把成句概率的阈值self.threshold设为 1 ，太高无法实现文本纠错的目的

5.nnlm_homework为nnlm语言模型，word_correction_homework为文本纠错的实现代码，
  “财经.pth”为模型训练好的参数，“vocab.txt” 为根据“财经.txt”构造的字表，其余为老师提供的文件
